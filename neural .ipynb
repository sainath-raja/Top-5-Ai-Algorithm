{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "27aOGzIaIwAL",
        "outputId": "c40a25c6-f5b7-49f8-afc3-5434e35dad93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.compile of <keras.src.engine.sequential.Sequential object at 0x7fe8aa77cd30>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.engine.training.Model.compile</b><br/>def compile(optimizer=&#x27;rmsprop&#x27;, loss=None, metrics=None, loss_weights=None, weighted_metrics=None, run_eagerly=None, steps_per_execution=None, jit_compile=None, pss_evaluation_shards=0, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py</a>Configures the model for training.\n",
              "\n",
              "Example:\n",
              "\n",
              "```python\n",
              "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
              "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
              "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
              "                       tf.keras.metrics.FalseNegatives()])\n",
              "```\n",
              "\n",
              "Args:\n",
              "    optimizer: String (name of optimizer) or optimizer instance. See\n",
              "      `tf.keras.optimizers`.\n",
              "    loss: Loss function. May be a string (name of loss function), or\n",
              "      a `tf.keras.losses.Loss` instance. See `tf.keras.losses`. A loss\n",
              "      function is any callable with the signature `loss = fn(y_true,\n",
              "      y_pred)`, where `y_true` are the ground truth values, and\n",
              "      `y_pred` are the model&#x27;s predictions.\n",
              "      `y_true` should have shape\n",
              "      `(batch_size, d0, .. dN)` (except in the case of\n",
              "      sparse loss functions such as\n",
              "      sparse categorical crossentropy which expects integer arrays of\n",
              "      shape `(batch_size, d0, .. dN-1)`).\n",
              "      `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
              "      The loss function should return a float tensor.\n",
              "      If a custom `Loss` instance is\n",
              "      used and reduction is set to `None`, return value has shape\n",
              "      `(batch_size, d0, .. dN-1)` i.e. per-sample or per-timestep loss\n",
              "      values; otherwise, it is a scalar. If the model has multiple\n",
              "      outputs, you can use a different loss on each output by passing a\n",
              "      dictionary or a list of losses. The loss value that will be\n",
              "      minimized by the model will then be the sum of all individual\n",
              "      losses, unless `loss_weights` is specified.\n",
              "    metrics: List of metrics to be evaluated by the model during\n",
              "      training and testing. Each of this can be a string (name of a\n",
              "      built-in function), function or a `tf.keras.metrics.Metric`\n",
              "      instance. See `tf.keras.metrics`. Typically you will use\n",
              "      `metrics=[&#x27;accuracy&#x27;]`.\n",
              "      A function is any callable with the signature `result = fn(y_true,\n",
              "      y_pred)`. To specify different metrics for different outputs of a\n",
              "      multi-output model, you could also pass a dictionary, such as\n",
              "      `metrics={&#x27;output_a&#x27;:&#x27;accuracy&#x27;, &#x27;output_b&#x27;:[&#x27;accuracy&#x27;, &#x27;mse&#x27;]}`.\n",
              "      You can also pass a list to specify a metric or a list of metrics\n",
              "      for each output, such as\n",
              "      `metrics=[[&#x27;accuracy&#x27;], [&#x27;accuracy&#x27;, &#x27;mse&#x27;]]`\n",
              "      or `metrics=[&#x27;accuracy&#x27;, [&#x27;accuracy&#x27;, &#x27;mse&#x27;]]`. When you pass the\n",
              "      strings &#x27;accuracy&#x27; or &#x27;acc&#x27;, we convert this to one of\n",
              "      `tf.keras.metrics.BinaryAccuracy`,\n",
              "      `tf.keras.metrics.CategoricalAccuracy`,\n",
              "      `tf.keras.metrics.SparseCategoricalAccuracy` based on the shapes\n",
              "      of the targets and of the model output. We do a similar\n",
              "      conversion for the strings &#x27;crossentropy&#x27; and &#x27;ce&#x27; as well.\n",
              "      The metrics passed here are evaluated without sample weighting; if\n",
              "      you would like sample weighting to apply, you can specify your\n",
              "      metrics via the `weighted_metrics` argument instead.\n",
              "    loss_weights: Optional list or dictionary specifying scalar\n",
              "      coefficients (Python floats) to weight the loss contributions of\n",
              "      different model outputs. The loss value that will be minimized by\n",
              "      the model will then be the *weighted sum* of all individual\n",
              "      losses, weighted by the `loss_weights` coefficients.  If a list,\n",
              "      it is expected to have a 1:1 mapping to the model&#x27;s outputs. If a\n",
              "      dict, it is expected to map output names (strings) to scalar\n",
              "      coefficients.\n",
              "    weighted_metrics: List of metrics to be evaluated and weighted by\n",
              "      `sample_weight` or `class_weight` during training and testing.\n",
              "    run_eagerly: Bool. If `True`, this `Model`&#x27;s logic will not be\n",
              "      wrapped in a `tf.function`. Recommended to leave this as `None`\n",
              "      unless your `Model` cannot be run inside a `tf.function`.\n",
              "      `run_eagerly=True` is not supported when using\n",
              "      `tf.distribute.experimental.ParameterServerStrategy`. Defaults to\n",
              "       `False`.\n",
              "    steps_per_execution: Int or `&#x27;auto&#x27;`. The number of batches to\n",
              "      run during each `tf.function` call. If set to &quot;auto&quot;, keras will\n",
              "      automatically tune `steps_per_execution` during runtime. Running\n",
              "      multiple batches inside a single `tf.function` call can greatly\n",
              "      improve performance on TPUs, when used with distributed strategies\n",
              "      such as `ParameterServerStrategy`, or with small models with a\n",
              "      large Python overhead. At most, one full epoch will be run each\n",
              "      execution. If a number larger than the size of the epoch is\n",
              "      passed, the execution will be truncated to the size of the epoch.\n",
              "      Note that if `steps_per_execution` is set to `N`,\n",
              "      `Callback.on_batch_begin` and `Callback.on_batch_end` methods will\n",
              "      only be called every `N` batches (i.e. before/after each\n",
              "      `tf.function` execution). Defaults to `1`.\n",
              "    jit_compile: If `True`, compile the model training step with XLA.\n",
              "      [XLA](https://www.tensorflow.org/xla) is an optimizing compiler\n",
              "      for machine learning.\n",
              "      `jit_compile` is not enabled for by default.\n",
              "      Note that `jit_compile=True`\n",
              "      may not necessarily work for all models.\n",
              "      For more information on supported operations please refer to the\n",
              "      [XLA documentation](https://www.tensorflow.org/xla).\n",
              "      Also refer to\n",
              "      [known XLA issues](https://www.tensorflow.org/xla/known_issues)\n",
              "      for more details.\n",
              "    pss_evaluation_shards: Integer or &#x27;auto&#x27;. Used for\n",
              "      `tf.distribute.ParameterServerStrategy` training only. This arg\n",
              "      sets the number of shards to split the dataset into, to enable an\n",
              "      exact visitation guarantee for evaluation, meaning the model will\n",
              "      be applied to each dataset element exactly once, even if workers\n",
              "      fail. The dataset must be sharded to ensure separate workers do\n",
              "      not process the same data. The number of shards should be at least\n",
              "      the number of workers for good performance. A value of &#x27;auto&#x27;\n",
              "      turns on exact evaluation and uses a heuristic for the number of\n",
              "      shards based on the number of workers. 0, meaning no\n",
              "      visitation guarantee is provided. NOTE: Custom implementations of\n",
              "      `Model.test_step` will be ignored when doing exact evaluation.\n",
              "      Defaults to `0`.\n",
              "    **kwargs: Arguments supported for backwards compatibility only.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 625);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert the target variable to one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 3)\n",
        "y_test = keras.utils.to_categorical(y_test, 3)\n",
        "\n",
        "# Build the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}